{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **05 - MLModelEvaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Train a machine learning regression model to predict the sale price of inherited houses and other properties in the region.\n",
        "* Answer business requirement 2:\n",
        "    * The client is interested in predicting the house sale price from her four inherited houses and any other house in Ames, Iowa.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/cleaned/HousePricesCleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports the Numpy and Pandas library and reads CSV file HousePricesRecordsCleaned.csv into DataFrame df and displays the first 15 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/cleaned/HousePricesCleaned.csv\")\n",
        "\n",
        "print(df.shape)\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports libraries for building a machine learning regression pipeline, incorporating feature engineering, preprocessing, and modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "from feature_engine import creation\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "  pipeline_base = Pipeline([\n",
        "    ('lt', vt.LogTransformer(variables = ['LotArea', 'GrLivArea']) ),\n",
        "\n",
        "    ('pt', vt.PowerTransformer(variables = ['GarageArea', 'MasVnrArea', 'OpenPorchSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF']) ),\n",
        "       \n",
        "      \n",
        "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=1.6, tail='both', \n",
        "                                                  variables=['1stFlrSF',\n",
        "                                                             '2ndFlrSF',\n",
        "                                                             'BsmtFinSF1',\n",
        "                                                             'BsmtUnfSF',\n",
        "                                                             'GarageArea',\n",
        "                                                             'GrLivArea',\n",
        "                                                             'LotArea',\n",
        "                                                             'MasVnrArea',\n",
        "                                                             'OpenPorchSF',\n",
        "                                                             'TotalBsmtSF'\n",
        "                                                      ])),      \n",
        "       \n",
        "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables= None,\n",
        "       method=\"spearman\", threshold=0.8,selection_method=\"variance\") ),\n",
        "\n",
        "    (\"feat_scaling\", StandardScaler() ),\n",
        "\n",
        "    (\"feat_selection\",  SelectFromModel(model) ),\n",
        "\n",
        "    (\"model\", model ),\n",
        "    ])\n",
        "\n",
        "  return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model=  PipelineOptimization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for g in self.grid_searches:\n",
        "            params = self.grid_searches[g].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[g].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[g].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(g, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splits the dataset into training and testing sets, with 20% of the data for testing, using train_test_split. The target variable SalePrice is separated from the features. Prints the column names and shapes of the training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['SalePrice'], axis=1),\n",
        "    df['SalePrice'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Columns in X_train:\", X_train.columns)\n",
        "print(\"Columns in X_test:\", X_test.columns)\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displays the first 15 rows to see the separation of both the training set (X_train) and the testing set (X_test) by using the head() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.head(15))\n",
        "print(X_test.head(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=42),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=42),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=42),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=42),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=42),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LinearRegression\": {},\n",
        "\n",
        "    \"DecisionTreeRegressor\": {\n",
        "        'model__max_depth': [None, 5, 16],\n",
        "        'model__min_samples_split': [3, 50],\n",
        "        'model__min_samples_leaf': [1, 50],\n",
        "        'model__max_leaf_nodes': [None, 50],\n",
        "    },\n",
        "\n",
        "    \"ExtraTreesRegressor\": {\n",
        "        'model__n_estimators': [100, 50, 150],\n",
        "        'model__max_depth': [None, 2, 20],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1, 50],\n",
        "    },\n",
        "\n",
        "    \"AdaBoostRegressor\": {\n",
        "        'model__n_estimators': [50, 25, 75, 160],\n",
        "        'model__learning_rate': [1, 0.05, 2],\n",
        "        'model__loss': ['linear', 'square', 'exponential'],\n",
        "    },\n",
        "\n",
        "    \"GradientBoostingRegressor\": {\n",
        "        'model__n_estimators': [100, 50, 150],\n",
        "        'model__learning_rate': [0.1, 0.01, 0.001],\n",
        "        'model__max_depth': [2, 20, None],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1, 50],\n",
        "        'model__max_leaf_nodes': [None, 50],\n",
        "    },\n",
        "\n",
        "    \"XGBRegressor\": {\n",
        "        'model__n_estimators': [30, 80, 220],\n",
        "        'model__max_depth': [None, 2, 20],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.001],\n",
        "        'model__gamma': [0, 0.1],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports the warnings module and suppresses the warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=72),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"ExtraTreesRegressor\":{'model__n_estimators': [50,100,150],\n",
        "        'model__max_depth': [None, 2, 20],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1,50],\n",
        "        },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Performs hyperparameter optimization to find the best model and hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selects the best performing model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selects the best parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selects the best estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set_theme(style='darkgrid')\n",
        "\n",
        "data_cleaning_feat_eng_steps = 8\n",
        "\n",
        "pipeline_steps = best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps]\n",
        "temp_pipeline = Pipeline(pipeline_steps)\n",
        "\n",
        "transformed_data = temp_pipeline.fit_transform(X_train)\n",
        "\n",
        "def get_feature_names_from_pipeline(pipeline_steps, X_train):\n",
        "    feature_names = X_train.columns  # Default to original feature names\n",
        "    \n",
        "    for name, transformer in pipeline_steps:\n",
        "        if hasattr(transformer, 'get_feature_names_out'):\n",
        "            feature_names = transformer.get_feature_names_out()\n",
        "    \n",
        "    return feature_names\n",
        "\n",
        "feature_names = get_feature_names_from_pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps], X_train)\n",
        "\n",
        "transformed_data = pd.DataFrame(transformed_data, columns=feature_names)\n",
        "\n",
        "if 'feat_selection' in best_regressor_pipeline.named_steps:\n",
        "    feat_selector = best_regressor_pipeline['feat_selection']\n",
        "    selected_columns = transformed_data.columns[feat_selector.get_support()]\n",
        "else:\n",
        "    selected_columns = transformed_data.columns\n",
        "\n",
        "if hasattr(best_regressor_pipeline['model'], 'feature_importances_'):\n",
        "    feature_importances = best_regressor_pipeline['model'].feature_importances_\n",
        "else:\n",
        "    print(\"Model does not have feature importances attribute. Skipping this step.\")\n",
        "    feature_importances = None\n",
        "\n",
        "if feature_importances is not None:\n",
        "    df_feature_importance = pd.DataFrame({\n",
        "        'Feature': selected_columns,\n",
        "        'Importance': feature_importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(f\"* These are the {len(df_feature_importance)} most important features in descending order: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "    df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No feature importance to plot.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error \n",
        "import numpy as np\n",
        "\n",
        "def regression_performance(X_train, y_train, X_test, y_test,pipeline):\n",
        "\tprint(\"Model Evaluation \\n\")\n",
        "\tprint(\"* Train Set\")\n",
        "\tregression_evaluation(X_train,y_train,pipeline)\n",
        "\tprint(\"* Test Set\")\n",
        "\tregression_evaluation(X_test,y_test,pipeline)\n",
        "\n",
        "def regression_evaluation(X, y, pipeline):\n",
        "  prediction = pipeline.predict(X)\n",
        "  print('R2 Score:', round(r2_score(y, prediction), 3))\n",
        "  print('Mean Absolute Error:', round(mean_absolute_error(y, prediction), 3))\n",
        "  print('Mean Squared Error:', round(mean_squared_error(y, prediction), 3))\n",
        "  print('Root Mean Squared Error:', round(np.sqrt(mean_squared_error(y, prediction)), 3))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "def regression_evaluation_plots(X_train, y_train, X_test, y_test,pipeline, alpha_scatter=0.5):\n",
        "  pred_train = pipeline.predict(X_train)\n",
        "  pred_test = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
        "  sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
        "  sns.lineplot(x=y_train , y=y_train, color='orange', ax=axes[0])\n",
        "  axes[0].set_xlabel(\"Actual\")\n",
        "  axes[0].set_ylabel(\"Predictions\")\n",
        "  axes[0].set_title(\"Train Set\")\n",
        "\n",
        "  sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
        "  sns.lineplot(x=y_test, y=y_test, color='orange', ax=axes[1])\n",
        "  axes[1].set_xlabel(\"Actual\")\n",
        "  axes[1].set_ylabel(\"Predictions\")\n",
        "  axes[1].set_title(\"Test Set\")\n",
        "  plt.savefig(f'docs/plots/regression_performance.png', bbox_inches='tight')  \n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best regressor model pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline(steps=[  \n",
        "    ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['GarageArea']) ),\n",
        "                                     \n",
        "    ('lt', vt.LogTransformer(variables = ['GrLivArea']) ),\n",
        "\n",
        "    ('pt', vt.PowerTransformer(variables = ['TotalBsmtSF']) ),\n",
        "      \n",
        "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=1.5, tail='both', \n",
        "                                                  variables=['GarageArea', 'TotalBsmtSF']) ),      \n",
        "\n",
        "    (\"feat_scaling\", StandardScaler() ),\n",
        "\n",
        "  ('model', ExtraTreesRegressor(max_depth=20, min_samples_split=50,\n",
        "                                     n_estimators=150, random_state=76))])        \n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Original columns in the dataset:\", df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_features = ['1stFlrSF', 'BsmtFinSF1', 'GarageArea', 'GarageYrBlt', 'GrLivArea', 'LotArea', 'OverallQual', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "missing_train_columns = [col for col in best_features if col not in X_train.columns]\n",
        "missing_test_columns = [col for col in best_features if col not in X_test.columns]\n",
        "\n",
        "if missing_train_columns:\n",
        "    print(f\"X-train is missing columns: {missing_train_columns}\")\n",
        "\n",
        "if missing_test_columns:\n",
        "    print(f\"X-test is missing columns: {missing_test_columns}\")\n",
        "\n",
        "if not missing_train_columns and not missing_test_columns:\n",
        "    X_train = X_train[best_features]\n",
        "    X_test = X_test[best_features]\n",
        "\n",
        "    print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\", X_test.shape, y_test.shape)\n",
        "    print(X_train.head(5))\n",
        "else:\n",
        "    print(\"There are columns missing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_search = {\n",
        "    \"ExtraTreesRegressor\": {\n",
        "        'model__n_estimators': [50, 100, 150],\n",
        "        'model__max_depth': [3, 5, 10],\n",
        "        'model__min_samples_split': [5, 10, 20],\n",
        "        'model__min_samples_leaf': [5, 10, 20],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieves a summary of the grid search results using the score_summary method from the search object, sorting the results by the mean score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selects best model from grid_search_summary DataFrame by accessing the first row and first column, which corresponds to the model with the highest mean score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieves the best regressor pipeline from grid_search_pipelines using the best model identifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_pipeline_regressor = grid_search_pipelines[best_model].best_estimator_\n",
        "best_pipeline_regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = 'v1'\n",
        "file_path = f'outputs/ml_pipeline/predict_price/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displays the first 15 rows of X_train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)\n",
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displays the first 15 rows of y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saves the X_test and y_test datasets as CSV files in the specified directory (file_path). The X_test data is saved as X_test.csv and the y_test data as y_test.csv, both without including row indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False) \n",
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the steps within the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_pipeline_regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prints the machine learning pipeline preprocessing and modeling steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(best_pipeline_regressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saves best_pipeline_regressor to a file using joblib. It serializes the pipeline object and stores it as regression_pipeline.pkl in a directory defined by file_path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(value=best_pipeline_regressor, filename=f\"{file_path}/regression_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creates a bar plot to visualize the feature importance of a machine learning model using the data stored in df_feature_importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creates a bar plot for feature importance and saves it as images in two specified locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')\n",
        "plt.savefig(f'docs/plots/features_importance.png', bbox_inches='tight') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prints the machine learning pipeline preprocessing and modeling steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(best_pipeline_regressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next Steps\n",
        "The Next Step is to create a Streamlit app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
